name: Build and Deploy Catalog Service

on:
  push:
    branches:
      - master
      - main
      - fase/quatro
  workflow_dispatch:
    inputs:
      environment:
        description: "Environment to deploy"
        required: true
        default: "dev"
        type: choice
        options:
          - dev

env:
  AWS_REGION: us-east-1
  ECR_REPOSITORY: catalog-service
  EKS_CLUSTER_NAME: tech-challenge-cluster
  JAVA_VERSION: "21"
  K8S_INFRA_REPO: "tech_challenge_k8s_infra"
  SERVICE_NAME: "catalog-service"

jobs:
  test:
    name: Test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      checks: write
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: "temurin"
          cache: maven

      - name: Run tests
        run: mvn clean test

      - name: Generate test report
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Maven Tests
          path: target/surefire-reports/*.xml
          reporter: java-junit

      - name: Generate coverage report
        run: mvn jacoco:report

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./target/site/jacoco/jacoco.xml
          flags: unittests
          name: catalog-service-coverage
          fail_ci_if_error: false

  build:
    name: Build and Push Docker Image
    needs: test
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read
    outputs:
      image_tag: ${{ steps.meta.outputs.tags }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up JDK 21
        uses: actions/setup-java@v4
        with:
          java-version: ${{ env.JAVA_VERSION }}
          distribution: "temurin"
          cache: maven

      - name: Build with Maven
        run: mvn clean package -DskipTests

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Configure AWS Credentials (assume OIDC role for deploy)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::124731138716:role/github-actions-deployer
          aws-region: ${{ env.AWS_REGION }}

      - name: Verify AWS credentials and list clusters
        run: |
          echo "Caller identity:"
          aws sts get-caller-identity || { echo "Invalid AWS credentials"; exit 1; }
          echo "EKS clusters in region ${{ env.AWS_REGION }}:"
          aws eks list-clusters --region ${{ env.AWS_REGION }} || true

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repository if not exists
        run: |
          aws ecr describe-repositories --repository-names ${{ env.ECR_REPOSITORY }} || \
          aws ecr create-repository --repository-name ${{ env.ECR_REPOSITORY }}

      - name: Extract metadata for Docker
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=${{ github.sha }}
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    name: Deploy to Dev
    needs: build
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS Credentials (assume OIDC role for rollback)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::124731138716:role/github-actions-deployer
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Retrieve Secrets from SSM
        id: ssm
        run: |
          echo "Retrieving parameters from SSM..."
          ENVIRONMENT=${{ github.event.inputs.environment || 'dev' }}

          # Helper to safely get parameter (returns empty string if not found)
          get_param() {
            aws ssm get-parameter --name "$1" --with-decryption --query "Parameter.Value" --output text 2>/dev/null || true
          }

          # Database credentials (may not exist for DynamoDB-backed deployments)
          DB_ENDPOINT=$(get_param "/microservices/$ENVIRONMENT/catalog-service-db/endpoint")
          if [ -n "$DB_ENDPOINT" ]; then
            DB_HOST=${DB_ENDPOINT%:*}
          else
            DB_HOST=""
          fi
          DB_PORT=$(get_param "/microservices/$ENVIRONMENT/catalog-service-db/port")
          DB_NAME=$(get_param "/microservices/$ENVIRONMENT/catalog-service-db/name")

          # EKS Cluster Name (fallback to env if param not found)
          EKS_CLUSTER_NAME=$(get_param "/microservices/$ENVIRONMENT/eks/cluster_name")
          if [ -z "$EKS_CLUSTER_NAME" ]; then
            EKS_CLUSTER_NAME="${{ env.EKS_CLUSTER_NAME }}"
          fi

          # Secure credentials
          DB_USER=$(get_param "/microservices/$ENVIRONMENT/catalog-service-db/username")
          DB_PASS=$(get_param "/microservices/$ENVIRONMENT/catalog-service-db/password")

          # Mask secrets if present
          if [ -n "$DB_USER" ]; then echo "::add-mask::$DB_USER"; fi
          if [ -n "$DB_PASS" ]; then echo "::add-mask::$DB_PASS"; fi

          # Export to environment (may be empty)
          echo "DB_HOST=$DB_HOST" >> $GITHUB_ENV
          echo "DB_PORT=$DB_PORT" >> $GITHUB_ENV
          echo "DB_NAME=$DB_NAME" >> $GITHUB_ENV
          echo "DB_USER=$DB_USER" >> $GITHUB_ENV
          echo "DB_PASS=$DB_PASS" >> $GITHUB_ENV
          echo "EKS_CLUSTER_NAME=$EKS_CLUSTER_NAME" >> $GITHUB_ENV

          echo "Secrets retrieval complete (missing parameters are allowed)."

      - name: Show retrieved environment variables
        run: |
          echo "EKS_CLUSTER_NAME=${{ env.EKS_CLUSTER_NAME }}"
          echo "AWS_REGION=${{ env.AWS_REGION }}"
          env | grep -E 'EKS_CLUSTER_NAME|AWS_REGION|DB_' || true

      - name: Configure kubectl
        run: |
          # Wait for EKS cluster to become ACTIVE (timeout ~10 minutes)
          MAX_RETRIES=30
          SLEEP_SEC=20
          status=""
          for i in $(seq 1 $MAX_RETRIES); do
            status=$(aws eks describe-cluster --name "${{ env.EKS_CLUSTER_NAME }}" --region "${{ env.AWS_REGION }}" --query "cluster.status" --output text 2>/dev/null || echo "")
            echo "EKS status: $status (attempt $i/$MAX_RETRIES)"
            if [ "$status" = "ACTIVE" ]; then
              break
            fi
            sleep $SLEEP_SEC
          done

          if [ "$status" != "ACTIVE" ]; then
            echo "Cluster not ACTIVE after $((MAX_RETRIES*SLEEP_SEC))s. Dumping cluster info for debugging."
            aws eks describe-cluster --name "${{ env.EKS_CLUSTER_NAME }}" --region "${{ env.AWS_REGION }}"
            exit 1
          fi

          aws eks update-kubeconfig --region "${{ env.AWS_REGION }}" --name "${{ env.EKS_CLUSTER_NAME }}"

      - name: Validate kubectl
        run: |
          echo "kubectl version and cluster-info"
          kubectl version --client || true
          kubectl cluster-info || { echo "kubectl cannot reach cluster; dumping kubeconfig"; kubectl config view --minify; exit 1; }
          kubectl get nodes -o wide || true

      - name: Create/Update Namespace
        run: |
          kubectl create namespace ${{ env.SERVICE_NAME }} --dry-run=client -o yaml | kubectl apply -f -

      - name: Create/Update Secrets with Database Credentials
        run: |
          # Build secret only with non-empty values (DB_* may be empty for DynamoDB deployments)
          SECRET_CMD="kubectl create secret generic catalog-service-secrets"
          if [ -n "${{ env.DB_HOST }}" ]; then SECRET_CMD+=" --from-literal=DB_HOST='${{ env.DB_HOST }}'"; fi
          if [ -n "${{ env.DB_PORT }}" ]; then SECRET_CMD+=" --from-literal=DB_PORT='${{ env.DB_PORT }}'"; fi
          if [ -n "${{ env.DB_NAME }}" ]; then SECRET_CMD+=" --from-literal=DB_NAME='${{ env.DB_NAME }}'"; fi
          if [ -n "${{ env.DB_USER }}" ]; then SECRET_CMD+=" --from-literal=DB_USERNAME='${{ env.DB_USER }}'"; fi
          if [ -n "${{ env.DB_PASS }}" ]; then SECRET_CMD+=" --from-literal=DB_PASSWORD='${{ env.DB_PASS }}'"; fi
          SECRET_CMD+=" --from-literal=JWT_SECRET='${{ secrets.JWT_SECRET }}'"
          SECRET_CMD+=" --from-literal=NEW_RELIC_LICENSE_KEY='${{ secrets.NEW_RELIC_LICENSE_KEY }}'"
          SECRET_CMD+=" --namespace=${{ env.SERVICE_NAME }} --dry-run=client -o yaml"

          # Execute and apply
          eval "$SECRET_CMD" | kubectl apply -f -

      - name: (skip) infra checkout removed
        run: echo "Using k8s manifests from this repository's k8s/ folder"

      - name: Deploy to EKS
        run: |
          cd k8s

          # Apply all manifests in this repo
          kubectl apply -k . -n ${{ env.SERVICE_NAME }}

          # Update image with correct tag
          kubectl set image deployment/catalog-service-deployment \
            catalog-service=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_REPOSITORY }}:${{ github.sha }} \
            -n ${{ env.SERVICE_NAME }}

          # Force imagePullPolicy to Always
          kubectl patch deployment catalog-service-deployment -n ${{ env.SERVICE_NAME }} \
            -p '{"spec":{"template":{"spec":{"containers":[{"name":"catalog-service","imagePullPolicy":"Always"}]}}}}'

      - name: Wait for deployment rollout
        run: |
          kubectl rollout status deployment/catalog-service-deployment -n ${{ env.SERVICE_NAME }} --timeout=10m

      - name: Verify deployment
        run: |
          echo "=== Pods Status ==="
          kubectl get pods -n ${{ env.SERVICE_NAME }}
          echo ""
          echo "=== Services ==="
          kubectl get svc -n ${{ env.SERVICE_NAME }}
          echo ""
          echo "=== HPA Status ==="
          kubectl get hpa -n ${{ env.SERVICE_NAME }}

      - name: Debug Deployment Failure
        if: failure()
        run: |
          echo "=========================================="
          echo "=== DEPLOYMENT FAILURE DEBUG INFO ==="
          echo "=========================================="
          kubectl get pods -n ${{ env.SERVICE_NAME }} -o wide
          kubectl describe deployment catalog-service-deployment -n ${{ env.SERVICE_NAME }}
          kubectl logs -l app=catalog-service -n ${{ env.SERVICE_NAME }} --tail=200 --all-containers=true || true
          kubectl get events -n ${{ env.SERVICE_NAME }} --sort-by='.lastTimestamp' | tail -30

  rollback:
    name: Rollback on Failure
    needs: [deploy]
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Configure kubectl
        run: |
          ENVIRONMENT=${{ github.event.inputs.environment || 'dev' }}
          CLUSTER=$(aws ssm get-parameter --name "/microservices/$ENVIRONMENT/eks/cluster_name" --query "Parameter.Value" --output text 2>/dev/null || echo "${{ env.EKS_CLUSTER_NAME }}")
          aws eks update-kubeconfig --region ${{ env.AWS_REGION }} --name $CLUSTER

      - name: Rollback deployment
        run: |
          echo "ðŸ”„ Rolling back deployment..."
          kubectl rollout undo deployment/catalog-service-deployment -n ${{ env.SERVICE_NAME }}
          kubectl rollout status deployment/catalog-service-deployment -n ${{ env.SERVICE_NAME }} --timeout=5m

      - name: Verify rollback
        run: |
          echo "âœ… Rollback completed"
          kubectl get pods -n ${{ env.SERVICE_NAME }}
